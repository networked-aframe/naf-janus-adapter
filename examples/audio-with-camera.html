<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Audio With Camera Example — naf-janus-adapter</title>
    <meta name="description" content="Audio With Camera Example — naf-janus-adapter" />

    <script src="https://aframe.io/releases/1.4.2/aframe.min.js" crossorigin="anonymous"></script>
    <script
      src="https://unpkg.com/networked-aframe@^0.11.0/dist/networked-aframe.min.js"
      crossorigin="anonymous"
    ></script>
    <script src="https://webrtc.github.io/adapter/adapter-latest.js" crossorigin="anonymous"></script>
    <script src="./dist/naf-janus-adapter.js"></script>
    <script src="./js/audio-system.js"></script>

    <script
      src="https://unpkg.com/aframe-randomizer-components@^3.0.1/dist/aframe-randomizer-components.min.js"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://unpkg.com/aframe-environment-component@1.3.2/dist/aframe-environment-component.min.js"
      crossorigin="anonymous"
    ></script>

    <script>
      // see issue https://github.com/networked-aframe/networked-aframe/issues/267
      NAF.schemas.getComponentsOriginal = NAF.schemas.getComponents;
      NAF.schemas.getComponents = (template) => {
        if (!NAF.schemas.hasTemplate("#avatar-template")) {
          NAF.schemas.add({
            template: "#avatar-template",
            components: [
              "position",
              "rotation",
              {
                selector: ".head",
                component: "material",
                property: "color",
              },
            ],
          });
        }
        const components = NAF.schemas.getComponentsOriginal(template);
        return components;
      };
    </script>
  </head>

  <body>
    <a-scene
      audio
      networked-scene="
        room: 1;
        debug: true;
        adapter: janus;
        connectOnLoad: true;
        serverURL: wss://preprod-janus.example.com/janus;
      "
    >
      <a-assets>
        <!-- Templates -->

        <!-- Avatar -->
        <template id="avatar-template">
          <a-entity class="avatar" networked-audio-source>
            <a-plane
              color="#fff"
              width="4"
              height="3"
              position="0 .6 0"
              material="side: back"
              networked-video-source
            ></a-plane>
            <a-sphere class="head" scale="0.45 0.5 0.4"></a-sphere>
            <a-entity class="face" position="0 0.05 0">
              <a-sphere class="eye" color="#efefef" position="0.16 0.1 -0.35" scale="0.12 0.12 0.12">
                <a-sphere class="pupil" color="#000" position="0 0 -1" scale="0.2 0.2 0.2"></a-sphere>
              </a-sphere>
              <a-sphere class="eye" color="#efefef" position="-0.16 0.1 -0.35" scale="0.12 0.12 0.12">
                <a-sphere class="pupil" color="#000" position="0 0 -1" scale="0.2 0.2 0.2"></a-sphere>
              </a-sphere>
            </a-entity>
          </a-entity>
        </template>

        <!-- /Templates -->
      </a-assets>

      <a-entity id="cameraRig">
        <a-entity
          id="player"
          networked="template:#avatar-template;attachTemplateToLocal:false;"
          camera
          position="0 1.6 0"
          wasd-controls
          look-controls
        >
          <a-sphere class="head" visible="false" random-color></a-sphere>
        </a-entity>
      </a-entity>

      <a-entity environment="preset:arches"></a-entity>
      <a-entity light="type:ambient;intensity:0.5"></a-entity>
    </a-scene>

    <style>
      .actions {
        position: absolute;
        display: flex;
        bottom: 3%;
        left: 3%;
      }

      .button {
        cursor: pointer;
        background: #fff;
        height: 40px;
        width: 130px;
        border-radius: 30px;
      }
    </style>

    <div class="actions">
      <button id="camera-btn" type="button" class="button">Show Camera</button>
      <button id="scene-btn" type="button" class="button">Start streaming scene</button>
    </div>

    <script>
      function genClientId() {
        return String(crypto.getRandomValues(new Uint32Array(1))[0]);
      }

      const state = {};
      state.currentStream = null;
      state.cameraEnabled = false;
      state.sceneStreamingEnabled = false;

      // Prompt for audio.
      document.addEventListener("DOMContentLoaded", () => {
        const scene = document.querySelector("a-scene");
        const cameraBtnEl = document.getElementById("camera-btn");
        const sceneBtnEl = document.getElementById("scene-btn");

        const stopAndRemoveVideoTrack = async () => {
          const videoTracks = state.currentStream.getVideoTracks();
          if (videoTracks.length > 0) {
            videoTracks[0].stop();
            state.currentStream.removeTrack(videoTracks[0]);
            await NAF.connection.adapter.setLocalMediaStream(state.currentStream);
          }
        };

        // Handle camera button click (Show and Hide)
        cameraBtnEl.addEventListener("click", async () => {
          if (state.sceneStreamingEnabled) {
            await stopAndRemoveVideoTrack();
            state.sceneStreamingEnabled = false;
            sceneBtnEl.textContent = "Start streaming scene";
          }

          if (state.cameraEnabled) {
            await stopAndRemoveVideoTrack();
          } else {
            const stream = await navigator.mediaDevices.getUserMedia({
              video: { mediaSource: "camera", width: { max: 1280, ideal: 640 }, height: { ideal: 360 }, frameRate: 30 },
            });
            state.currentStream.addTrack(stream.getVideoTracks()[0]);
            await NAF.connection.adapter.setLocalMediaStream(state.currentStream);
          }

          state.cameraEnabled = !state.cameraEnabled;
          cameraBtnEl.textContent = state.cameraEnabled ? "Hide Camera" : "Show Camera";
        });

        // Handle scene streaming button click (Start and Stop)
        sceneBtnEl.addEventListener("click", async () => {
          if (state.cameraEnabled) {
            await stopAndRemoveVideoTrack();
            state.cameraEnabled = false;
            cameraBtnEl.textContent = "Show Camera";
          }

          if (state.sceneStreamingEnabled) {
            await stopAndRemoveVideoTrack();
          } else {
            const stream = scene.canvas.captureStream(30);
            state.currentStream.addTrack(stream.getVideoTracks()[0]);
            await NAF.connection.adapter.setLocalMediaStream(state.currentStream);
          }

          state.sceneStreamingEnabled = !state.sceneStreamingEnabled;
          sceneBtnEl.textContent = state.sceneStreamingEnabled ? "Stop streaming scene" : "Start streaming scene";
        });

        scene.addEventListener("adapter-ready", ({ detail: adapter }) => {
          // We don't use the syncOccupants API, set requestedOccupants to be the same array instance as availableOccupants
          adapter.requestedOccupants = adapter.availableOccupants;
          const clientId = genClientId(); // generate a random 16 characters string, but you can use a uuid4 for example
          adapter.setClientId(clientId);
          navigator.mediaDevices
            .getUserMedia({ audio: true })
            .then((stream) => {
              adapter.setLocalMediaStream(stream).then(() => {
                // Note that networked-scene audio:true option has no effect with the janus adapter
                adapter.enableMicrophone(true); // set it to false if you want to be muted initially.
                state.currentStream = stream;
                adapter.setLocalMediaStream(stream);
              });
            })
            .catch((err) => {
              console.warn("Microphone access not allowed. This client will not broadcast audio.");
            });
        });
      });

      // Called by Networked-Aframe when connected to server
      function onConnect() {
        console.log("onConnect", new Date());
      }
    </script>
  </body>
</html>
